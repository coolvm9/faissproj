{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea15b4-0780-4dac-9d8d-138e117aca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c97e4d6a-e37e-46ce-9e5c-1c4ee953fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import shutil\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356ac233-a7f6-4f40-b3c8-243bd9bb8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear Hugging Face cache\n",
    "def clear_huggingface_cache():\n",
    "    cache_dir = os.path.expanduser('~/.cache/huggingface')\n",
    "    if os.path.exists(cache_dir):\n",
    "        shutil.rmtree(cache_dir)\n",
    "    os.makedirs(cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e895f1d-b019-4f3e-b27b-74464c789acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the Hugging Face cache to ensure a clean environment\n",
    "clear_huggingface_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e698606c-56e9-43c9-b265-42478de9f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific FutureWarning from huggingface_hub\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='huggingface_hub.file_download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0a3ca68-2033-4246-bb28-eded1deaa52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted index file: faiss_index.index\n"
     ]
    }
   ],
   "source": [
    "# Function to clear the FAISS index in memory\n",
    "def clear_faiss_index(dimension):\n",
    "    return faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Function to delete index files from disk\n",
    "def delete_index_files(index_path, metadata_path):\n",
    "    # Remove the index file\n",
    "    if os.path.exists(index_path):\n",
    "        os.remove(index_path)\n",
    "        print(f\"Deleted index file: {index_path}\")\n",
    "\n",
    "    # Remove the metadata file\n",
    "    if os.path.exists(metadata_path):\n",
    "        os.remove(metadata_path)\n",
    "        print(f\"Deleted metadata file: {metadata_path}\")\n",
    "\n",
    "# Initialize variables\n",
    "dimension = 384  # Use the appropriate dimension for your vectors\n",
    "index_path = 'faiss_index.index'\n",
    "metadata_path = 'metadata.pkl'\n",
    "\n",
    "# Clear the FAISS index in memory\n",
    "index = clear_faiss_index(dimension)\n",
    "\n",
    "# Delete index files from disk\n",
    "delete_index_files(index_path, metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "527d3fe8-7e9d-4b16-a578-b8802c824dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/satyaanumolu/POCs/faissproj\n",
      "File sample_data.csv exists.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Data from CSV\n",
    "csv_file_path = 'sample_data.csv'  # Replace with the path to your CSV file\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(csv_file_path):\n",
    "    print(f\"File {csv_file_path} exists.\")\n",
    "else:\n",
    "    print(f\"File {csv_file_path} does not exist. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e67e3f17-b6a4-4eda-b89e-321fb9f980a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully.\n",
      "DataFrame content:\n",
      "   id                                               text   source\n",
      "0   1         This is a document about machine learning.     Book\n",
      "1   2  Here we discuss the basics of artificial intel...  Article\n",
      "2   3  This text is all about natural language proces...     Book\n",
      "3   4    Deep learning techniques are advancing rapidly.  Article\n",
      "4   5             AI is transforming various industries.   Report\n",
      "5   6  Machine learning provides systems the ability ...  Article\n",
      "6   7  Understanding AI and ML is crucial for modern ...     Book\n",
      "7   8  Data science integrates domain knowledge progr...   Report\n",
      "8   9  Big data and analytics are essential for extra...  Article\n",
      "9  10  The future of AI includes ethical consideratio...     Book\n",
      "DataFrame columns:\n",
      "Index(['id', 'text', 'source'], dtype='object')\n",
      "Data extracted from CSV:\n",
      "['This is a document about machine learning.', 'Here we discuss the basics of artificial intelligence.', 'This text is all about natural language processing.', 'Deep learning techniques are advancing rapidly.', 'AI is transforming various industries.', 'Machine learning provides systems the ability to learn and improve from experience.', 'Understanding AI and ML is crucial for modern technology.', 'Data science integrates domain knowledge programming skills and math.', 'Big data and analytics are essential for extracting insights.', 'The future of AI includes ethical considerations and challenges.']\n",
      "Sources extracted from CSV:\n",
      "['Book', 'Article', 'Book', 'Article', 'Report', 'Article', 'Book', 'Report', 'Article', 'Book']\n"
     ]
    }
   ],
   "source": [
    "# Try to read the CSV file\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    print(\"CSV file loaded successfully.\")\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(\"DataFrame content:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Display the DataFrame columns\n",
    "    print(\"DataFrame columns:\")\n",
    "    print(df.columns)\n",
    "\n",
    "    # Assuming the CSV has a column named 'text' that you want to index\n",
    "    texts = df['text'].tolist()\n",
    "    sources = df['source'].tolist()\n",
    "    print(\"Data extracted from CSV:\")\n",
    "    print(texts)\n",
    "    print(\"Sources extracted from CSV:\")\n",
    "    print(sources)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ba0b703-b69c-46f5-88a5-9f39a5a9aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert Text Data to Vectors using Sentence Transformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "vectors = model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "847fd9e5-b5a6-44b6-8ae9-aba02b30ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a FAISS Index and Add Vectors\n",
    "dimension = vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 (Euclidean) distance\n",
    "index.add(np.array(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e191fab9-debd-4bb1-864c-860265fd5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index and metadata for later use\n",
    "index_path = 'faiss_index.index'\n",
    "metadata_path = 'metadata.pkl'\n",
    "\n",
    "faiss.write_index(index, index_path)\n",
    "\n",
    "# Save metadata (e.g., texts and sources)\n",
    "metadata = {'texts': texts, 'sources': sources}\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "955e5ece-9766-4871-92aa-f943cfc10b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Query the Index\n",
    "def query_faiss(query_text, top_k=5):\n",
    "    query_vector = model.encode([query_text])\n",
    "    distances, indices = index.search(np.array(query_vector), top_k)\n",
    "    return [(metadata['texts'][idx], metadata['sources'][idx], distances[0][i]) for i, idx in enumerate(indices[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5843e18-36f1-41bd-ba10-4bfd133983d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Query\n",
    "query = \"Big data and analytics essental for ? \"\n",
    "results = query_faiss(query, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "174f6721-ddb5-4753-b90b-b84229ef2cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Big data and analytics are essential for extracting insights., Source: Article, Distance: 0.6674928069114685\n",
      "Document: Data science integrates domain knowledge programming skills and math., Source: Report, Distance: 1.2074646949768066\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for text, source, distance in results:\n",
    "    print(f\"Document: {text}, Source: {source}, Distance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb45e7d-b265-41bc-b181-c6bac7a56ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the index and metadata back (if needed)\n",
    "def load_index_and_metadata(index_path, metadata_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(metadata_path, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    return index, metadata\n",
    "\n",
    "# Usage of the load function\n",
    "index, metadata = load_index_and_metadata(index_path, metadata_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
